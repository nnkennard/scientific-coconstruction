{
  "identifier": "IsHQmuOqRAG",
  "reviews": [
    {
      "review_id": "csQKLOEZWJ1",
      "sentences": [
        "Overall, I found the paper quite interesting.",
        "I think the optical flow based warping to predict some subset of the pixels in the next timestep is in itself an important contribution and this paper would be a good addition to the emerging literature on unsupervised object-centric models.",
        "I think the main concern with the paper is limited experimental evaluation.",
        "The model is evaluated only on a single, rather simple dataset (that was generated by the authors).",
        "I know these models cannot usually handle complicated datasets so it's fine to have a simple dataset but I'd have liked to see the model evaluated on some of the datasets that other competing models were evaluated on.",
        "Some of those datasets might not have camera information etc.",
        "but I'm sure there are other datasets that have the necessary information (e.g., see [1], [2] for some potential datasets).",
        "Also, the authors mention that their technique is the first to infer 3D position of objects while segmenting images.",
        "If I'm not mistaken, [1] also does both and would be a great model to compare against.",
        "Other notes",
        "- Std deviations in table 1 are too large.",
        "Is this a typo?",
        "If not, it looks like all models are doing equally well.",
        "- I don't have any specific recommendations here but I found the model description a bit hard to follow.",
        "It might be a good idea to do another pass and see if it can be organized better.",
        "For example, the fact that warping and imagination are combined to get the final image can be mentioned earlier so the reader knows where/how the imagination network is used.",
        "-",
        "There are many inline equations; these make it difficult to parse the text visually.",
        "It would be nice to take these out of the text and split the long section 2.3.1 to subsections and mark these.",
        "- Figure 1 is great but again hard to parse.",
        "Perhaps adding variable names (i.e., x, p, z etc.) to the figure might make it easier to understand what goes in and out of each network.",
        "[1] Henderson, Paul, and Christoph H. Lampert.",
        "2020. \u201cUnsupervised Object-Centric Video Generation and Decomposition in 3D.\u201d arXiv [cs.CV].",
        "arXiv.",
        "http://arxiv.org/abs/2007.06705.\n[2]",
        "Kabra et al., 2021. \"SIMONe: View-Invariant, Temporally-Abstracted Object Representations via Unsupervised Video Decomposition\", https://arxiv.org/abs/2106.03849"
      ],
      "rating": "5: marginally below the acceptance threshold",
      "reviewer": "Reviewer_8qC3",
      "tcdate": 1635890319834
    },
    {
      "review_id": "WrDeHjS3hiC",
      "sentences": [
        "Strengths",
        "I like the general thrust of this paper.",
        "While the basic idea has been around in cognitive psychology, which inspired the authors, I am not aware of any significant implementation of it.",
        "This is a nice first step.",
        "To make this work, the authors develop some algorithmic bits that might be useful for followup work.",
        "The results compare well to others in this space, showing that the training strategy has real promise.",
        "In some sense, the methods are not really comparable as the other methods do not have a viable way to make use of the additional training data.",
        "(Also see comment about number of objects below).",
        "Weaknesses",
        "The paper is harder to read than needed.",
        "I appreciate there is a lot of stuff going, and I believe I was able to get most of it after a few iterations, so the lack of clarity is not extreme.",
        "It is not clear how differing numbers of objects are handled.",
        "It seems that the number of objects might simply be provided (K=3 in the dataset)?",
        "But if the number of objects is known, then the comparison to other work that infers it might not be fair.",
        "K is in the pseudo code, but does not seam inferred.",
        "Should K be an input.",
        "A few more details on the LSTM would help.",
        "The paper could use some polishing.",
        "Figure 1, which is informative and key, could be tidied up.",
        "Also, I am guessing that the \"Objects\" box is the LSTM.",
        "The English could be improved in places, and there are a number of grammar errors (e.g., the first two uses of \"pixel\" in 2.3.1 should be \"pixels\", and 'This last two terms mean' on page 5).",
        "The authors do not say whether they will release their code.",
        "Comments",
        "A clear limitation of this work is that the data is synthetic and very simple (although perhaps more complex than other work in this space).",
        "The authors acknowledge this in their discussion.",
        "While this might be the standard for this sub-area, real data from a robot or car should be relatively easy to get.",
        "Easy block-world-like real data might be better for pushing the work than adding more texture and diverse lighting in synthetic data.",
        "Using just two time points is both a strength and a weakness.",
        "With just two, there is likely to be a lot of ambiguity between translation and rotation, especially if you generalize to more than one pose parameter.",
        "Looking at the effect of larger training sequences would be interesting.",
        "While the part of the system that is deployed at testing is a simple network, there are a number of hand constructed components (e.g., the warping function) that make use of what we know about cameras, it would be more interesting to see those learned."
      ],
      "rating": "8: accept, good paper",
      "reviewer": "Reviewer_uocA",
      "tcdate": 1635877254212
    },
    {
      "review_id": "K8Z332m28Qn",
      "sentences": [
        "Overall, this paper is messily written, and proposes something that only works marginally better than prior methods, on a synthetic toy dataset.",
        "The performance in Table 1 illustrates this: the standard deviation of the segmentation IOU (0.34) is about even with the average IOU (0.35)!",
        "Looking at the qualitative results in Figure 2, it seems the model often misses objects completely, and produces segmentations that are fractional and have holes.",
        "I appreciate that the baselines are doing badly here also, but slot attention had very similar ARI-fg (0.42+-0.35 vs 0.46+-0.39).",
        "Statistically maybe these are equivalent.",
        "Is it possible at least to show that this method does better on the datasets where those previous papers managed to work (like CLEVR and those deepmind shapes datasets)?",
        "In general this area of work seems stuck in a setup where all methods work well on different toy data, but no methods work on real images or videos.",
        "It seems like the pose estimation is not working at all, judging by Figure 3-E.",
        "The discussion mentions this too: \"object spatial location is inferred more easily than object pose (which we have not fully investigated), thus the predicted warping relies more on object translation than rotation\".",
        "Maybe the object pose estimation can be removed from the paper entirely, to make things simpler.",
        "\"our framework can easily generalize to 3D pose\" I am sure the formulation can easily be extended to capture this, but I would prefer that the wording here be a bit more careful, to not suggest that the model is expected to work when pitch and roll are unknowns as well.",
        "(If you do expect it to work, please try it out and add the results to the paper.)",
        "\"At time t, given the location of the camera o(t) \u2208 R3 and its facing direction \u03b1(t)\"",
        "Does this mean the camera intrinsics and extrinsics are assumed known?",
        "It would be great to say this directly.",
        "The discussion section supports this interpretation, saying \"additional information required is that of observer\u2019s self-motion, which is available both in the brain as efference copy and easily accessible in vehicles\".",
        "I do not really buy the argument about the brain, or easy accessibility in vehicles.",
        "Self-driving vehicles usually register themselves to a known map; inferring pose from odometry alone causes drift.",
        "The LSTM reading objects from the full-frame encoding sounds like a very weak part of the model.",
        "Why not, for example, use a standard object detector, like MaskRCNN?",
        "I know you want to be self-supervised, but then why not self-supervise a well-known architecture that is proven to work, instead of inventing a new one?",
        "\"The location prediction is restricted to the range of possible value within the virtual environment by logistic function and linear scaling\" I don't know what this means.",
        "The imagination network is clumsily introduced.",
        "The first instance of it is already \"the imagination network\", and the motivation for it is only written in the caption of Figure1.",
        "I found a helpful description later on in page5.",
        "These things should be re-arranged.",
        "The description of the unprojection of a 2D coordinate into 3D space looks odd to me.",
        "Where is this coming from?",
        "Given that i,j are coordinates, what do |i| and |j| represent?",
        "Normally we start from x=fX/Z, and then invert this to X=Zx/f, where x is 2D and X is 3D, and f is the focal length.",
        "I am also not sure how the first term and second term here are able to multiply, since the first term is a 2-tuple (i,j) and the third term is a 3-tuple (i,d,j).",
        "I also got lost in the angular velocity equation.",
        "It seems the sum is over all \\gamma1, all \\gamma2, and all differences of the two within 2\\pi of \\omega.",
        "This is too many things to sum over!",
        "It seems like you won't end up with a valid probability distribution.",
        "I am probably misreading the notation here.",
        "In any case, why is this probability distribution useful?",
        "The object-based imagination network seems to require a scalar here for the rotational speed.",
        "So why not take the expectation of the first pose distribution, expectation of the second, and then take a difference?",
        "It is interesting that you do not use depth supervision, but for toy settings like this I think it is OK to assume depth is known, and focus on other hard parts, like segmentation and tracking.",
        "I need some help understanding L_{spatial}.",
        "The second term is described as a contrastive loss, but it's a difference between known positions and random positions.",
        "Why is this a good idea, and why is it contrastive?",
        "Normally a contrastive loss compares two estimates and pushes them apart (rather than pulling every estimate to random).",
        "I was surprised that the evaluation talked about a model called \"OPPLE\" (\"Only OPPLE shows a bi-modal distribution.\").",
        "Apparently this is the name of the proposed model, and the place to learn this is the caption of Figure 1!",
        "Please do not put critical information exclusively in figure captions.",
        "Typos: \n- probability mess -> probability mass \n- generated dataset -> generated a dataset\n- states-of-art -> state-of-the-art\n- network appear to -> network appears to\n- intersectin (in fig3) -> intersection\n- Figure 1 is never referred to in the text"
      ],
      "rating": "5: marginally below the acceptance threshold",
      "reviewer": "Reviewer_iu2Y",
      "tcdate": 1635910536880
    },
    {
      "review_id": "FLQMvcWmzpu",
      "sentences": [
        "# Strength",
        "1. The paper tackles the difficult problem of learning to segment objects from an image using no supervision during training.",
        "2. The problem setting and motivation for this task are explained clearly.",
        "A detailed description of the method, along with a pseudocode of the learning algorithm is provided in the paper.",
        "3. The paper introduces a new synthetic dataset of images taken from scenes with multiple objects with varying shapes and textures (11 and 15, respectively).",
        "4. Figures 3A-D are very helpful explaining the quantitative performance of the method in relation to the baselines.",
        "Figures 3E-G are also helpful showing the failure modes of the proposed method.",
        "# Weakness",
        "1. I am not fully convinced that the comparison to the baselines is entirely fair.",
        "If I understand correctly, the rest of the methods were trained on single images without having access to previous and next frames.",
        "While I appreciate the method\u2019s usage of consecutive frames as part of the supervision, I think this should be stated clearly when comparing with the baselines -- to avoid any overclaims.",
        "SynSin [1], for example, also predicts the next frame\u2019s RGB and depth images without using additional supervision.",
        "Similar to the proposed method in this paper, SynSin synthesizes future images given their camera poses by warping the current frame using differentiable rendering.",
        "Combining an object-centric approach (like slot-attention) with such a method that performs future image prediction would make a fairer comparison, in my opinion.",
        "[1]",
        "Wiles, O., Gkioxari, G., Szeliski, R. and Johnson, J., 2020.",
        "Synsin: End-to-end view synthesis from a single image.",
        "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 7467-7477).",
        "2. I think there are some key references missing in the paper too.",
        "For instance, a paper from last year also learns an object-centric representation in an unsupervised fashion to decompose the objects in a scene while estimating their poses in 3D [2].",
        "How does [2] compare to the method presented in this paper?",
        "What are the main differences between them?",
        "[2]",
        "Henderson, P. and Lampert, C.H., 2020.",
        "Unsupervised object-centric video generation and decomposition in 3D.",
        "Advances in Neural Information Processing Systems, 33.",
        "3. The results are reported using only the dataset introduced in the paper.",
        "I suggest including results from datasets like the Objects Room or CLEVR, where the existing methods (MONet, Slot-attention, Genesis, [2]) have already reported results on.",
        "4. There are no ablation studies reported in the paper.",
        "Some parts of the loss function seem redundant judging from their current descriptions.",
        "I think it would be very helpful either presenting additional results by ablating the loss function / part of the model, or detail in the text why the method needs each of those components.",
        "# Recommended Decision",
        "I think in its current form the paper is not ready to be published.",
        "I strongly encourage the authors to clarify the positioning of this paper in relation to the state-of-the-art (see my comment on weaknesses).",
        "I vote for [reject, not good enough] for now, but I would be happy to increase my rating once the authors clear up my concerns.",
        "# Additional Feedback",
        "1. It should be \\hat(m) instead of \\hat(t) in the L_spatial loss\u2019 third term.",
        "2. What is x_rand?",
        "If they are randomly sampled point positions then what is their underlying distribution?",
        "3. Have you tested the method on scenes with more than 3 objects?",
        "Slot attention, for instance, is able to segment up to 9 objects.",
        "Since the paper introduces a new dataset, I would\u2019ve hoped to see a more challenging benchmark with a wider variety of objects and number of instances.",
        "4. Also, the dataset assumes that the camera moves with constant pose change.",
        "Have you tested the motion prediction (position, orientation and their time-derivatives) in the presence of different camera velocities?",
        "If not, are there any limitations of the method that prevents it?",
        "5. I suggest adding the equivalents of Figure 3G for each baseline in the appendix.",
        "6. What is the number of bins for the yaw angle prediction, b? Have you tried using a continuous representation for the rotation?",
        "7. What does the predicted image (I\u2019) for the next time-step look like?",
        "I suggest including more qualitative results to the paper for evaluating the warping function.",
        "8. I think it is a good idea to introduce a more diverse benchmarking dataset for learning object-centric representations.",
        "However, I think the dataset proposed in the paper should be further expanded by including more daily life objects, instead of just geometric primitives like spheres, prisms and cones.",
        "I suggest taking a look at datasets like YCB or ShapeNet to include more realistic objects to your dataset."
      ],
      "rating": "3: reject, not good enough",
      "reviewer": "Reviewer_Z7dM",
      "tcdate": 1635967416294
    }
  ],
  "decision": "Reject",
  "conference": "iclr_2022",
  "urls": {
    "forum": "https://openreview.net/forum?id=IsHQmuOqRAG",
    "initial": "https://openreview.net/references/pdf?id=IsP_70hkhIy",
    "final": "https://openreview.net/references/pdf?id=KG8pYV-7Hy"
  }
}